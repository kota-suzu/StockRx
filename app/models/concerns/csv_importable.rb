# frozen_string_literal: true

module CsvImportable
  extend ActiveSupport::Concern

  # ã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰
  module ClassMethods
    def import_from_csv(file_path, options = {})
      require "csv"
      require "digest/md5"

      options = prepare_import_options(options)
      result = process_csv_import(file_path, options)

      Rails.logger.info("CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: #{result[:valid_count] + result[:update_count]}ä»¶å–è¾¼, #{result[:invalid_records].size}ä»¶ã‚¨ãƒ©ãƒ¼")
      result
    end

    # CSVã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
    def export_to_csv(records = nil, options = {})
      require "csv"

      records ||= all
      headers = options[:headers] || column_names

      CSV.generate do |csv|
        csv << headers

        records.find_each do |record|
          csv << headers.map { |header| record.send(header) }
        end
      end
    end

    private

    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®æº–å‚™
    def prepare_import_options(options)
      default_options = {
        batch_size: 1000,
        headers: true,
        skip_invalid: false,
        column_mapping: {},
        update_existing: false,
        unique_key: "name"
      }

      default_options.merge(options)
    end

    # CSVå‡¦ç†ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†
    def process_csv_import(file_path, options)
      valid_records = []
      invalid_records = []
      update_records = []

      Rails.logger.info("CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹: #{file_path}")

      # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¾ãŸã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
      file_path = file_path.respond_to?(:path) ? file_path.path : file_path

      ActiveRecord::Base.transaction do
        process_csv_rows(file_path, options, valid_records, invalid_records, update_records)

        # æ®‹ã‚Šã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‡¦ç†
        bulk_insert(valid_records) if valid_records.present?
        bulk_update(update_records) if update_records.present?
      end

      {
        valid_count: valid_records.size,
        update_count: update_records.size,
        invalid_records: invalid_records
      }
    end

    # CSVã®å„è¡Œã‚’å‡¦ç†
    def process_csv_rows(file_path, options, valid_records, invalid_records, update_records)
      CSV.foreach(file_path, headers: options[:headers], encoding: "UTF-8") do |row|
        attributes = row_to_attributes(row, options[:column_mapping])

        existing_record = find_existing_record(row, options)

        if existing_record
          process_existing_record(existing_record, attributes, update_records, invalid_records, row)
        else
          process_new_record(attributes, valid_records, invalid_records, row, options[:skip_invalid])
        end

        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰ãƒãƒ«ã‚¯ã‚¤ãƒ³ã‚µãƒ¼ãƒˆ/æ›´æ–°
        if valid_records.size >= options[:batch_size]
          bulk_insert(valid_records)
          valid_records.clear
        end

        if update_records.size >= options[:batch_size]
          bulk_update(update_records)
          update_records.clear
        end
      end
    end

    # è¡Œãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å±æ€§ãƒãƒƒã‚·ãƒ¥ã¸ã®å¤‰æ›
    def row_to_attributes(row, column_mapping)
      attributes = {}

      # ãƒãƒƒãƒ”ãƒ³ã‚°ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãã®ã¾ã¾å¤‰æ›
      if column_mapping.blank?
        row.to_h.each do |key, value|
          attributes[key] = value if key.present? && column_names.include?(key.to_s)
        end
      else
        # ãƒãƒƒãƒ”ãƒ³ã‚°ã«å¾“ã£ã¦å¤‰æ›
        column_mapping.each do |from, to|
          attributes[to.to_s] = row[from.to_s] if row[from.to_s].present?
        end
      end

      attributes
    end

    # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ¤œç´¢
    def find_existing_record(row, options)
      return nil unless options[:update_existing] && row[options[:unique_key]].present?

      # å®‰å…¨ãªã‚¯ã‚¨ãƒªã®ãŸã‚ã«è¨±å¯ã•ã‚ŒãŸã‚«ãƒ©ãƒ åã‹ãƒã‚§ãƒƒã‚¯
      if %w[name code sku barcode].include?(options[:unique_key])
        # ã‚·ãƒ³ãƒœãƒ«ã‚’ã‚«ãƒ©ãƒ åã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ã§SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã‚’é˜²æ­¢
        where({ options[:unique_key].to_sym => row[options[:unique_key]] }).first
      else
        # è¨±å¯ã•ã‚Œã¦ã„ãªã„ã‚«ãƒ©ãƒ åã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®nameã‚’ä½¿ç”¨
        Rails.logger.warn("ä¸æ­£ãªunique_keyãŒæŒ‡å®šã•ã‚Œã¾ã—ãŸ: #{options[:unique_key]} - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®'name'ã‚’ä½¿ç”¨ã—ã¾ã™")
        where(name: row["name"]).first
      end
    end

    # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å‡¦ç†
    def process_existing_record(record, attributes, update_records, invalid_records, row)
      record.assign_attributes(attributes)

      if record.valid?
        update_records << record
      else
        invalid_records << { row: row, errors: record.errors.full_messages }
      end
    end

    # æ–°è¦ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å‡¦ç†
    def process_new_record(attributes, valid_records, invalid_records, row, skip_invalid)
      record = new(attributes)

      if record.valid?
        valid_records << record
      else
        invalid_records << { row: row, errors: record.errors.full_messages }
        nil if skip_invalid
      end
    rescue ArgumentError => e
      # enumå€¤ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
      if e.message.include?("is not a valid")
        invalid_records << { row: row, errors: [ e.message ] }
      else
        raise e
      end
      nil if skip_invalid
    end

    # æœ‰åŠ¹ãªãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒãƒ«ã‚¯ã‚¤ãƒ³ã‚µãƒ¼ãƒˆã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰
    def bulk_insert(records)
      return if records.blank?

      # æŒ¿å…¥ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å±æ€§ã‚’åé›†
      attributes = records.map do |record|
        record.attributes.except("id", "created_at", "updated_at")
      end

      # åœ¨åº«ãƒ­ã‚°ä½œæˆã®ãŸã‚ã€æŒ¿å…¥å‰ã®æœ€å¤§IDã‚’è¨˜éŒ²
      baseline_max_id = maximum(:id) || 0 if self.name == "Inventory"

      # Rails 7+ã®å ´åˆã¯insert_allã§record_timestamps: trueã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨
      result = insert_all(attributes, record_timestamps: true)

      # åœ¨åº«ãƒ­ã‚°ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆbulk_insertã§ã¯é€šå¸¸ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒå‹•ä½œã—ãªã„ãŸã‚ï¼‰
      if self.name == "Inventory"
        # MySQLã¨PostgreSQLã®å·®ç•°ã«å¯¾å¿œã—ãŸæ­£ç¢ºãªIDãƒãƒƒãƒ”ãƒ³ã‚°
        create_accurate_inventory_logs(records, result, baseline_max_id)
      end

      result
    end

    private

    # ã‚ˆã‚Šæ­£ç¢ºãªåœ¨åº«ãƒ­ã‚°ä½œæˆï¼ˆåå‰ã®é‡è¤‡ã«å¯¾å¿œï¼‰
    def create_accurate_inventory_logs(records, insert_result, baseline_max_id)
      return if records.blank?

      # PostgreSQLã®å ´åˆã¯RETURNINGå¥ã§IDã‚’å–å¾—
      if insert_result.respond_to?(:rows) && insert_result.rows.present?
        inserted_ids = insert_result.rows.flatten
        create_bulk_inventory_logs(records, inserted_ids)
      else
        # MySQLã®å ´åˆï¼šç›´æ¥çš„ãªIDãƒãƒƒãƒ”ãƒ³ã‚°å®Ÿè£…
        create_mysql_inventory_logs_direct(records, baseline_max_id)
      end
    end

    # PostgreSQLç”¨ã®åŠ¹ç‡çš„ãªä¸€æ‹¬ãƒ­ã‚°ä½œæˆ
    def create_bulk_inventory_logs(records, inserted_ids)
      return if records.blank? || inserted_ids.blank?

      log_entries = []

      records.each_with_index do |record, index|
        # ãƒ¬ã‚³ãƒ¼ãƒ‰ã¨æŒ¿å…¥ã•ã‚ŒãŸIDã‚’1:1ã§ãƒãƒƒãƒ”ãƒ³ã‚°
        inventory_id = inserted_ids[index]
        next unless inventory_id

        log_entries << {
          inventory_id: inventory_id,
          delta: record.quantity,
          operation_type: "add",
          previous_quantity: 0,
          current_quantity: record.quantity,
          note: "CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆã«ã‚ˆã‚‹ç™»éŒ²",
          created_at: Time.current,
          updated_at: Time.current
        }
      end

      if log_entries.present?
        InventoryLog.insert_all(log_entries, record_timestamps: false)
        Rails.logger.info("CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: #{log_entries.size}ä»¶ã®åœ¨åº«ãƒ­ã‚°ã‚’ä½œæˆ")
      end
    end

    # MySQLç”¨ã®ç›´æ¥çš„ãªIDãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å†…ã§å®‰å…¨ï¼‰
    def create_mysql_inventory_logs_direct(records, baseline_max_id)
      log_entries = []

      # insert_allå¾Œã®æ–°ã—ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ç¯„å›²ã§å–å¾—
      # ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å†…ã§ã‚‚COMMITã•ã‚Œã¦ã„ã‚‹ã®ã§æ¤œç´¢å¯èƒ½
      new_records = where("id > ?", baseline_max_id).order(:id).limit(records.size)

      # ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’é †åºã§å¯¾å¿œã•ã›ã‚‹ï¼ˆåŒã˜é †åºã§æŒ¿å…¥ã•ã‚Œã‚‹ã¯ãšï¼‰
      records.each_with_index do |record, index|
        inserted_record = new_records[index]

        if inserted_record
          log_entries << {
            inventory_id: inserted_record.id,
            delta: record.quantity,
            operation_type: "add",
            previous_quantity: 0,
            current_quantity: record.quantity,
            note: "CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆã«ã‚ˆã‚‹ç™»éŒ²",
            created_at: Time.current,
            updated_at: Time.current
          }
        else
          Rails.logger.warn("CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆ: ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°å¤±æ•— #{record.name}")
        end
      end

      if log_entries.present?
        InventoryLog.insert_all(log_entries, record_timestamps: false)
        Rails.logger.info("CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: #{log_entries.size}ä»¶ã®åœ¨åº«ãƒ­ã‚°ã‚’ä½œæˆ")
      end
    end

    # MySQLç”¨ã®ãƒãƒƒãƒæŒ¿å…¥å¾Œã®ç¢ºå®ŸãªIDãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆè¤‡é›‘ç‰ˆ - ä»Šå›ã¯ä½¿ç”¨ã—ãªã„ï¼‰
    def create_mysql_inventory_logs_with_transaction(records)
      puts "=== MySQLåœ¨åº«ãƒ­ã‚°ä½œæˆé–‹å§‹ ==="
      puts "records count: #{records.size}"

      # TODO: ğŸŸ¡ é‡è¦ - Phase 2ï¼ˆæ¨å®š1æ—¥ï¼‰- MySQLã§ã®ç¢ºå®ŸãªIDãƒãƒƒãƒ”ãƒ³ã‚°å®Ÿè£…
      # å•é¡Œ: å¾“æ¥ã®åå‰ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã§ã¯è¤‡æ•°ã®åŒåå•†å“ãŒã‚ã‚‹å ´åˆã«ä¸æ­£ç¢º
      # è§£æ±ºç­–: æŒ¿å…¥å‰å¾Œã®IDç¯„å›²ã¨ãƒãƒƒã‚·ãƒ¥å€¤ã‚’çµ„ã¿åˆã‚ã›ãŸç¢ºå®Ÿãªãƒãƒƒãƒ”ãƒ³ã‚°
      #
      # ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹é©ç”¨:
      # - ãƒãƒƒãƒæŒ¿å…¥ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒ
      # - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å›ºæœ‰æ©Ÿèƒ½ã®æŠ½è±¡åŒ–
      # - ç«¶åˆçŠ¶æ…‹ã«å¯¾ã™ã‚‹å …ç‰¢æ€§
      # - ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£ã®ç¢ºä¿

      log_entries = []

      ActiveRecord::Base.transaction do
        # æŒ¿å…¥å‰ã®æœ€å¤§IDã‚’è¨˜éŒ²ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
        baseline_max_id = maximum(:id) || 0
        puts "baseline_max_id: #{baseline_max_id}"

        # å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ï¼ˆè­˜åˆ¥ç”¨ï¼‰
        records_with_hash = records.map.with_index do |record, index|
          # è¤‡æ•°ã®å±æ€§ã‚’çµ„ã¿åˆã‚ã›ãŸãƒãƒƒã‚·ãƒ¥å€¤ã§ä¸€æ„æ€§ã‚’ç¢ºä¿
          hash_source = "#{record.name}_#{record.price}_#{record.quantity}_#{index}"
          hash_value = Digest::MD5.hexdigest(hash_source)

          {
            record: record,
            index: index,
            hash_value: hash_value
          }
        end

        Rails.logger.debug("records_with_hash prepared: #{records_with_hash.size}")

        # æŒ¿å…¥ç›´å¾Œã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒãƒƒã‚·ãƒ¥å€¤ã§ç¢ºå®Ÿã«ç‰¹å®š
        # æ³¨æ„: ã“ã®æ–¹æ³•ã¯ãƒãƒƒãƒæŒ¿å…¥ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ä¿æŒã™ã‚‹ãŒã€
        # å®Œå…¨ã«åŒä¸€ã®å•†å“ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯ä¾ç„¶ã¨ã—ã¦åˆ¶é™ãŒã‚ã‚‹
        start_time = Time.current

        records_with_hash.each do |item|
          record = item[:record]
          Rails.logger.debug("å‡¦ç†ä¸­ãƒ¬ã‚³ãƒ¼ãƒ‰: #{record.name}")

          # æœ€ã‚‚ç¢ºå®Ÿãªæ–¹æ³•ï¼šæŒ¿å…¥ç›´å¾Œã®ä¸€æ„ãªçµ„ã¿åˆã‚ã›ã§æ¤œç´¢
          search_conditions = {
            name: record.name,
            price: record.price,
            quantity: record.quantity
          }

          # æŒ¿å…¥å¾Œã®æ™‚é–“ç¯„å›²ã§çµã‚Šè¾¼ã¿ï¼ˆç«¶åˆã‚’æœ€å°åŒ–ï¼‰
          candidate_records = where(search_conditions)
                              .where("id > ?", baseline_max_id)
                              .where("created_at >= ?", start_time - 1.second)
                              .order(:id)

          Rails.logger.debug("candidate_records count: #{candidate_records.count}")

          if candidate_records.count == 1
            # ä¸€æ„ã«ç‰¹å®šã§ããŸå ´åˆ
            inserted_record = candidate_records.first
            Rails.logger.debug("ä¸€æ„ã«ç‰¹å®š: #{inserted_record.id}")
          elsif candidate_records.count > 1
            # è¤‡æ•°è©²å½“ã™ã‚‹å ´åˆã¯æœ€åˆã®ã‚‚ã®ï¼ˆè­¦å‘Šãƒ­ã‚°å‡ºåŠ›ï¼‰
            inserted_record = candidate_records.first
            Rails.logger.warn("CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆ: è¤‡æ•°ã®å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚#{record.name} (ID: #{inserted_record.id})")
          else
            # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒ­ã‚°å‡ºåŠ›ï¼‰
            Rails.logger.error("CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆ: ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚#{record.name}")
            Rails.logger.debug("æ¤œç´¢æ¡ä»¶: #{search_conditions}")
            Rails.logger.debug("baseline_max_id: #{baseline_max_id}, start_time: #{start_time}")
            next
          end

          log_entries << {
            inventory_id: inserted_record.id,
            delta: record.quantity,
            operation_type: "add",
            previous_quantity: 0,
            current_quantity: record.quantity,
            note: "CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆã«ã‚ˆã‚‹ç™»éŒ²",
            created_at: Time.current,
            updated_at: Time.current
          }
        end

        Rails.logger.debug("log_entries count: #{log_entries.size}")

        # ãƒãƒƒãƒã§åœ¨åº«ãƒ­ã‚°ã‚’æŒ¿å…¥
        if log_entries.present?
          InventoryLog.insert_all(log_entries, record_timestamps: false)
          Rails.logger.info("CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: #{log_entries.size}ä»¶ã®åœ¨åº«ãƒ­ã‚°ã‚’ä½œæˆ")
        else
          Rails.logger.warn("åœ¨åº«ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        end
      end

    rescue => e
      Rails.logger.error("CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: #{e.message}")
      raise e  # ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®ãŸã‚å†ã‚¹ãƒ­ãƒ¼
    end

    # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒãƒ«ã‚¯æ›´æ–°ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰
    def bulk_update(records)
      return if records.blank?

      records.each do |record|
        # ãƒ¬ã‚³ãƒ¼ãƒ‰æ›´æ–°ï¼ˆafter_saveã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒç™ºç«ï¼‰
        record.save!
      end
    rescue => e
      Rails.logger.error("ãƒãƒ«ã‚¯æ›´æ–°ã‚¨ãƒ©ãƒ¼: #{e.message}")
      raise e # ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ãŸã‚å†ã‚¹ãƒ­ãƒ¼
    end

    # TODO: ğŸ”µ é•·æœŸ - Phase 4ï¼ˆæ¨å®š2-3é€±é–“ï¼‰- CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½ã®åŒ…æ‹¬çš„æ‹¡å¼µ
    #
    # 1. é«˜åº¦ãªãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½
    #    - ã‚«ã‚¹ã‚¿ãƒ ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ«ã®è¨­å®š
    #    - è¤‡æ•°ã‚«ãƒ©ãƒ é–“ã®ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    #    - å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã®è‡ªå‹•æ¤œè¨¼
    #    - ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ãæ¤œè¨¼ï¼ˆåœ¨åº«æ•°é‡ã®å¦¥å½“æ€§ç­‰ï¼‰
    #
    # 2. ã‚¤ãƒ³ãƒãƒ¼ãƒˆé€²æ—ã®å¯è¦–åŒ–æ”¹å–„
    #    - WebSocketã‚’æ´»ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤º
    #    - ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¸ãƒ§ãƒ–ã§ã®éåŒæœŸå®Ÿè¡Œ
    #    - é€²æ—é€šçŸ¥ã®ãƒ¡ãƒ¼ãƒ«é€ä¿¡æ©Ÿèƒ½
    #    - ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½
    #
    # 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®é«˜åº¦åŒ–
    #    - ã‚¨ãƒ©ãƒ¼è¡Œã®è©³ç´°ãªç‰¹å®šæ©Ÿèƒ½ï¼ˆè¡Œç•ªå·ã€ã‚«ãƒ©ãƒ åã€å€¤ï¼‰
    #    - ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã®ãŸã‚ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½
    #    - éƒ¨åˆ†ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å†å®Ÿè¡Œæ©Ÿèƒ½
    #    - CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼ã®å¼·åŒ–
    #
    # 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
    #    - å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ10ä¸‡è¡Œä»¥ä¸Šï¼‰ã®åŠ¹ç‡çš„å‡¦ç†
    #    - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ï¼‰
    #    - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®åŠ¹ç‡çš„åˆ©ç”¨
    #    - ãƒãƒƒãƒã‚µã‚¤ã‚ºã®å‹•çš„èª¿æ•´
    #
    # 5. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–
    #    - ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã®å³æ ¼ãªæ¤œè¨¼
    #    - æ‚ªæ„ã®ã‚ã‚‹ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã®æ¤œå‡º
    #    - ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®ç´°ã‹ã„åˆ¶å¾¡
    #    - ç›£æŸ»ãƒ­ã‚°ã®å……å®Ÿ
    #
    # 6. å›½éš›åŒ–å¯¾å¿œ
    #    - å¤šè¨€èªã§ã®åˆ—åå¯¾å¿œ
    #    - ãƒ­ã‚±ãƒ¼ãƒ«åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œ
    #    - é€šè²¨ãƒ»æ—¥ä»˜å½¢å¼ã®è‡ªå‹•å¤‰æ›
    #
    # 7. å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ é€£æº
    #    - APIçµŒç”±ã§ã®ãƒ‡ãƒ¼ã‚¿åŒæœŸ
    #    - FTP/SFTPã§ã®è‡ªå‹•ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
    #    - ä»–ã‚·ã‚¹ãƒ†ãƒ ã¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›
    #
    # 8. æ¨ªå±•é–‹ç¢ºèªäº‹é …
    #    - ä»–ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆReceipt, Shipmentç­‰ï¼‰ã§ã®åŒæ§˜æ©Ÿèƒ½ã®å®Ÿè£…
    #    - å…±é€šã®CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆåŸºç›¤ã‚¯ãƒ©ã‚¹ã®ä½œæˆ
    #    - ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½ã®ãƒ—ãƒ©ã‚¬ãƒ–ãƒ«åŒ–
    #    - ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ©Ÿèƒ½ã®è¿½åŠ ï¼ˆæ¥­ç•Œæ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œï¼‰
  end
end
